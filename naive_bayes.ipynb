{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Naive Bayes Classifier using only NumPy and Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_col(df):\n",
    "    _df = pd.read_csv(df)\n",
    "    return _df.drop(\"Unnamed: 0\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_genre(df, genre):\n",
    "    df['genre'] = genre\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_df = pd.concat([\n",
    "    add_genre(pd.read_csv(\"lyrics_datasets\\ArianaGrande.csv\"), 'pop'),\n",
    "    add_genre(filter_col(\"lyrics_datasets\\CardiB.csv\"), 'rap'),\n",
    "    add_genre(filter_col(\"lyrics_datasets\\EdSheeran.csv\"), 'pop'),\n",
    "    add_genre(filter_col(\"lyrics_datasets\\Eminem.csv\"), 'rap'),\n",
    "    add_genre(filter_col(r\"lyrics_datasets\\NickiMinaj.csv\"), 'rap'),\n",
    "    add_genre(filter_col(\"lyrics_datasets\\TaylorSwift.csv\"), 'pop'),\n",
    "], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_df.drop(['Artist', 'Title', 'Date', 'Year', 'Album'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lyric    6\n",
       "genre    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lyric</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thought i'd end up with sean but he wasn't a m...</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yeah breakfast at tiffany's and bottles of bub...</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you you love it how i move you you love it how...</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ariana grande  nicki minaj i've been here all ...</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>right now i'm in a state of mind i wanna be in...</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Lyric genre\n",
       "0  thought i'd end up with sean but he wasn't a m...   pop\n",
       "1  yeah breakfast at tiffany's and bottles of bub...   pop\n",
       "2  you you love it how i move you you love it how...   pop\n",
       "3  ariana grande  nicki minaj i've been here all ...   pop\n",
       "4  right now i'm in a state of mind i wanna be in...   pop"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = lyrics_df['Lyric']\n",
    "y = lyrics_df['genre']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import stopwords\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(lyric):\n",
    "    nopunc = ''.join([char for char in lyric if char not in string.punctuation])\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_df.to_csv('lyrics.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pop    0.540581\n",
       "rap    0.459419\n",
       "Name: genre, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_df['genre'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer =  TfidfVectorizer(stop_words='english')\n",
    "X_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9898"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.vocabulary_['happy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.141775643617753"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.idf_[9898]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = X_train.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10875569761723804\n",
      "0.07478830450442232\n",
      "0.036550893346083434\n",
      "0.05082351383617261\n",
      "0.07151203573503453\n",
      "0.07793222155094921\n",
      "0.13663297757687332\n",
      "0.025798678942807494\n",
      "0.031149884260393838\n",
      "0.04467779147830858\n",
      "0.0996096643146941\n",
      "0.15622901531752154\n",
      "0.04045083043218156\n",
      "0.6008389155440812\n",
      "0.05718994067805746\n",
      "0.4055456174754732\n",
      "0.049963650630360124\n",
      "0.08583413079201159\n",
      "0.07421575697108532\n",
      "0.09487036669693713\n",
      "0.12568610077934267\n",
      "0.10015622584898867\n",
      "0.03700645881618444\n",
      "0.05010308011696966\n",
      "0.0182207499127651\n",
      "0.08722598630760962\n",
      "0.04604105825910031\n",
      "0.07225718326775896\n",
      "0.18712067584993605\n",
      "0.1926148190925277\n",
      "0.05671583269457126\n",
      "0.04505296939155293\n",
      "0.09334396269596842\n",
      "0.15359578977417215\n",
      "0.07478830450442232\n",
      "0.09111998994406313\n",
      "0.04955409235996377\n",
      "0.062475799830109\n",
      "0.06211861220638274\n",
      "0.06782466307788956\n",
      "0.08583413079201159\n",
      "0.07793222155094921\n",
      "0.10015622584898867\n",
      "0.06401128222928654\n",
      "0.06401128222928654\n",
      "0.047222127650445506\n",
      "0.07917473582931214\n",
      "0.08382454040934786\n",
      "0.03616025639747288\n",
      "0.04733499876876013\n",
      "0.14843151394217063\n",
      "0.09487036669693713\n",
      "0.0908785305816958\n",
      "0.12885035034789347\n",
      "0.026582225716043798\n",
      "0.03973542970695217\n",
      "0.04877166561187771\n",
      "0.13515890817465878\n",
      "0.027172214753455402\n",
      "0.07304751813421208\n",
      "0.08382454040934786\n",
      "0.12568610077934267\n",
      "0.11939660384280598\n"
     ]
    }
   ],
   "source": [
    "for word in range(len(lst)):\n",
    "    if (lst[word] != 0):\n",
    "        print(lst[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[5].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3b33d48af627876ac544114dd0fbe5a6124b6236eace591dad2ce23808c5c16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
