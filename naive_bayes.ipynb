{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier from scratch (only NumPy and Pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('datasets/lyrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_col(df):\n",
    "    _df = pd.read_csv(df)\n",
    "    return _df.drop(\"Unnamed: 0\", axis = 1)\n",
    "\n",
    "def add_genre(df, genre):\n",
    "    df['genre'] = genre\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_df = pd.concat([\n",
    "    add_genre(pd.read_csv(\"datasets\\lyrics_datasets\\EdSheeran.csv\"), 'pop'),\n",
    "    add_genre(filter_col(\"datasets\\lyrics_datasets\\CardiB.csv\"), 'rap'),\n",
    "    add_genre(filter_col(\"datasets\\lyrics_datasets\\Eminem.csv\"), 'rap'),\n",
    "    add_genre(filter_col(\"datasets\\lyrics_datasets\\TaylorSwift.csv\"), 'pop'),\n",
    "], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1371 entries, 0 to 478\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  296 non-null    float64\n",
      " 1   Artist      1371 non-null   object \n",
      " 2   Title       1371 non-null   object \n",
      " 3   Album       982 non-null    object \n",
      " 4   Year        983 non-null    float64\n",
      " 5   Date        983 non-null    object \n",
      " 6   Lyric       1367 non-null   object \n",
      " 7   genre       1371 non-null   object \n",
      "dtypes: float64(2), object(6)\n",
      "memory usage: 96.4+ KB\n"
     ]
    }
   ],
   "source": [
    "lyrics_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>Album</th>\n",
       "      <th>Year</th>\n",
       "      <th>Date</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>÷ (Divide)</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>the club isn't the best place to find a lover ...</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>÷ (Divide)</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2017-03-03</td>\n",
       "      <td>i found a love for me oh darling just dive rig...</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>Castle on the Hill</td>\n",
       "      <td>÷ (Divide)</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>when i was six years old i broke my leg i was ...</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>Happier</td>\n",
       "      <td>÷ (Divide)</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2017-03-03</td>\n",
       "      <td>walking down 9th and park i saw you in another...</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>Supermarket Flowers</td>\n",
       "      <td>÷ (Divide)</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2017-03-03</td>\n",
       "      <td>i took the supermarket flowers from the window...</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      Artist                Title       Album    Year  \\\n",
       "0         0.0  Ed Sheeran         Shape of You  ÷ (Divide)  2017.0   \n",
       "1         1.0  Ed Sheeran              Perfect  ÷ (Divide)  2017.0   \n",
       "2         2.0  Ed Sheeran   Castle on the Hill  ÷ (Divide)  2017.0   \n",
       "3         3.0  Ed Sheeran              Happier  ÷ (Divide)  2017.0   \n",
       "4         4.0  Ed Sheeran  Supermarket Flowers  ÷ (Divide)  2017.0   \n",
       "\n",
       "         Date                                              Lyric genre  \n",
       "0  2017-01-06  the club isn't the best place to find a lover ...   pop  \n",
       "1  2017-03-03  i found a love for me oh darling just dive rig...   pop  \n",
       "2  2017-01-06  when i was six years old i broke my leg i was ...   pop  \n",
       "3  2017-03-03  walking down 9th and park i saw you in another...   pop  \n",
       "4  2017-03-03  i took the supermarket flowers from the window...   pop  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping other columns, as predictions are to be made only based on lyrics\n",
    "\n",
    "lyrics_df.drop(['Unnamed: 0','Artist', 'Title', 'Date', 'Year', 'Album'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lyric    4\n",
       "genre    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "def clean(lyric):\n",
    "    ''' \n",
    "    removes punctuation and stopwords\n",
    "    '''\n",
    "    nopunc = ''.join([char for char in lyric if char not in string.punctuation])\n",
    "    return ' '.join([word for word in nopunc.split() if word.lower() not in stopwords.words('english')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_df['Lyric'] = lyrics_df['Lyric'].apply(lambda x: clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lyric</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>club isnt best place find lover bar go friends...</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>found love oh darling dive right follow lead w...</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>six years old broke leg running brother friend...</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>walking 9th park saw anothers arm month weve a...</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>took supermarket flowers windowsill threw day ...</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Lyric genre\n",
       "0  club isnt best place find lover bar go friends...   pop\n",
       "1  found love oh darling dive right follow lead w...   pop\n",
       "2  six years old broke leg running brother friend...   pop\n",
       "3  walking 9th park saw anothers arm month weve a...   pop\n",
       "4  took supermarket flowers windowsill threw day ...   pop"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_df.to_csv('cleaned_lyrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/cleaned_lyrics.csv')\n",
    "\n",
    "df.rename(columns = {'genre':'Genre'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['Lyric']\n",
    "y = df['Genre']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class for multinomial naive bayes classifier\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, alpha = 1):\n",
    "        # dict of datasets split based on label\n",
    "        self.category_dfs = {}\n",
    "\n",
    "        # finds prior probabilities of all labels (P(rap) and P(pop))\n",
    "        self.prior_probs = {}\n",
    "\n",
    "        # number of words in all documents under each label (N(rap) and N(pop))\n",
    "        self.label_counts = {}\n",
    "\n",
    "        # smoothing parameter (eliminates zero probability)\n",
    "        self.alpha = alpha\n",
    "\n",
    "        # dict of probabilities of a particular word, given that they are from that label (P(w/rap), p(w/pop))\n",
    "        self.label_parameters = {}\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        ''' \n",
    "        fits the model based on training data\n",
    "        '''\n",
    "        df = pd.concat([X,y], axis = 1)\n",
    "        self.fit_(df)\n",
    "\n",
    "    def length_of_doc(self, val):\n",
    "        ''' \n",
    "        number of words in a document\n",
    "        '''\n",
    "        return len(val.split())\n",
    "\n",
    "    def clean(self, lyric):\n",
    "        ''' \n",
    "        removes stopwords and punctuation\n",
    "        '''\n",
    "        nopunc = ''.join([char for char in lyric if char not in string.punctuation])\n",
    "        return ' '.join([word for word in nopunc.split() if word.lower() not in stopwords.words('english')])\n",
    "\n",
    "    def fit_(self, df):\n",
    "        ''' \n",
    "        fits dataframe, calculates all parameters for model\n",
    "        '''\n",
    "        y = df.iloc[:,-1]\n",
    "        X = df.iloc[:,:2]\n",
    "        X = X[X.columns[0]]\n",
    "        self.target = df.columns[-1]\n",
    "        self.labels = y.unique()\n",
    "\n",
    "        # finding set of vocablulary\n",
    "        vocab = []\n",
    "        for doc in X:\n",
    "            for word in doc.split():\n",
    "                if word not in vocab:\n",
    "                    vocab.append(word)\n",
    "        self.vocabulary = vocab\n",
    "        self.n_vocab = len(self.vocabulary) # N(vocab)\n",
    "\n",
    "        # count vectorisation\n",
    "        wc_df = self.generate_word_count(X)\n",
    "        X.index = X.index.sort_values()\n",
    "        y.index = y.index.sort_values()\n",
    "        clean_df = pd.concat([X, y, wc_df], axis = 1)\n",
    "        clean_df = clean_df.dropna()\n",
    "\n",
    "        # splitting training data based on label\n",
    "        for label in self.labels:\n",
    "            label_df = clean_df[clean_df[self.target] == label]\n",
    "            self.category_dfs[label] = label_df\n",
    "\n",
    "        # calculating prior probabilities and number of words in each doc\n",
    "        for label in self.labels:\n",
    "            label_prob = len(self.category_dfs[label])/len(clean_df)\n",
    "            self.prior_probs[label] = label_prob\n",
    "            words_per_label = self.category_dfs[label][self.target].apply(lambda x: self.length_of_doc(x))\n",
    "            self.label_counts[label] = words_per_label.sum()\n",
    "        \n",
    "        # calculating p(w/label) for every word in every label\n",
    "        for label in self.labels:\n",
    "            parameters_label = {unique_word:0 for unique_word in self.vocabulary}\n",
    "            for word in self.vocabulary:\n",
    "                n_word_given_label = self.category_dfs[label][word].sum()\n",
    "                p_word_given_label = (n_word_given_label + self.alpha) / (self.label_counts[label] + self.alpha*self.n_vocab)\n",
    "                parameters_label[word] = p_word_given_label\n",
    "            self.label_parameters[label] = parameters_label\n",
    "\n",
    "    def _predict(self, doc):\n",
    "        ''' \n",
    "        gives prediction for a single document\n",
    "        '''\n",
    "        doc = self.clean(doc)\n",
    "        doc = doc.split()\n",
    "        label_scores = {}\n",
    "\n",
    "        # p(label) * p(w1/label) * p(w2/label) * .....\n",
    "        for label in self.labels:\n",
    "            p_label_given_doc = self.prior_probs[label]\n",
    "            label_scores[label] = p_label_given_doc\n",
    "        for word in doc:\n",
    "            for label in self.labels:\n",
    "                if word in self.label_parameters[label]:\n",
    "                    # multiplying by 1000 to prevent probabilities to approximate to 0 if they become too small \n",
    "                    label_scores[label] *= (self.label_parameters[label][word]*(1000))\n",
    "        return self.max_dict(label_scores)\n",
    "\n",
    "    def max_dict(self, d):\n",
    "        ''' \n",
    "        finds key with max value in a dictionary\n",
    "        '''\n",
    "        rev = dict(map(reversed, d.items()))\n",
    "        return rev[max(list(d.values()))]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        ''' \n",
    "        predicts for a set of docs\n",
    "        '''\n",
    "        preds = []\n",
    "        for i in X:\n",
    "            preds.append(self._predict(i))\n",
    "        return preds\n",
    "\n",
    "    def generate_word_count(self, X):\n",
    "        ''' \n",
    "            count-vectorizes the documents in corpus\n",
    "        '''\n",
    "        word_count = {word: [0] * len(X) for word in self.vocabulary}\n",
    "        for index, doc in enumerate(X):\n",
    "            for word in doc.split():\n",
    "                word_count[word][index] += 1\n",
    "        word_count = pd.DataFrame(word_count)\n",
    "        return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = NaiveBayesClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shail\\AppData\\Local\\Temp\\ipykernel_16772\\3494719523.py:64: RuntimeWarning: overflow encountered in double_scalars\n",
      "  label_scores[label] *= (self.label_parameters[label][word]*(1000))\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pop       0.59      0.99      0.73       160\n",
      "         rap       0.50      0.02      0.03       114\n",
      "\n",
      "    accuracy                           0.58       274\n",
      "   macro avg       0.54      0.50      0.38       274\n",
      "weighted avg       0.55      0.58      0.44       274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy may be improved usiong Tfidf instead of Count vectorizing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3b33d48af627876ac544114dd0fbe5a6124b6236eace591dad2ce23808c5c16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
